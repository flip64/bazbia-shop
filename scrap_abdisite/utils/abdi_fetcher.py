import requests
from bs4 import BeautifulSoup
import logging
import re
from datetime import datetime

logger = logging.getLogger(__name__)

# Ú©Ø´ Ø³Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ù†Ú¯Ù‡Ø¯Ø§Ø±ÛŒ soup Ù‡Ø§
_soup_cache = {}

def get_soup(url):
    """Ø¯Ø±ÛŒØ§ÙØª ÛŒØ§ Ø¨Ø§Ø²Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù† BeautifulSoup Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ ÛŒÚ© URL"""
    if url in _soup_cache:
        soup = _soup_cache[url]
        if getattr(soup, "source_url", None) == url:
            return soup

    headers = {"User-Agent": "Mozilla/5.0"}
    resp = requests.get(url, headers=headers, timeout=10)
    resp.raise_for_status()

    soup = BeautifulSoup(resp.text, "html.parser")
    soup.source_url = url
    _soup_cache[url] = soup
    print("send request")
    return soup

def clean_price(price_str):
    if not price_str:
        return None
    digits = re.sub(r"[^\d]", "", price_str)
    return int(digits) if digits else None

def send_price_alert(name, new_price, old_price):
    """Ø§Ø±Ø³Ø§Ù„ Ù‡Ø´Ø¯Ø§Ø± ØªØºÛŒÛŒØ± Ù‚ÛŒÙ…Øª (ÙØ¹Ù„Ø§Ù‹ ÙÙ‚Ø· Ú†Ø§Ù¾ Ø¯Ø± Ú©Ù†Ø³ÙˆÙ„)"""
    change_percent = 0
    if old_price and old_price > 0 and new_price is not None:
        diff = new_price - old_price
        change_percent = (diff / old_price) * 100

    message = (
        f"ğŸš¨ ØªØºÛŒÛŒØ± Ù‚ÛŒÙ…Øª Ø¨Ø±Ø§ÛŒ Ù…Ø­ØµÙˆÙ„ {name or 'Ù†Ø§Ù…Ø´Ø®Øµ'}\n"
        f"ğŸ’° Ù‚ÛŒÙ…Øª Ù‚Ø¨Ù„ÛŒ: {old_price or 'Ù†Ø§Ù…Ø´Ø®Øµ'} ØªÙˆÙ…Ø§Ù†\n"
        f"ğŸ’µ Ù‚ÛŒÙ…Øª Ø¬Ø¯ÛŒØ¯: {new_price or 'Ù†Ø§Ù…Ø´Ø®Øµ'} ØªÙˆÙ…Ø§Ù†\n"
        f"ğŸ“Š ØªØºÛŒÛŒØ±: {change_percent:+.2f}%"
    )

    print(message)
    return {"console": "sent"}

def extract_specifications(url):
    soup = get_soup(url)
    feature_list = []

    section_title = soup.find(text=lambda t: "ÙˆÛŒÚ˜Ú¯ÛŒ Ù‡Ø§ÛŒ Ù…Ø­ØµÙˆÙ„" in t)
    if section_title:
        ul = section_title.find_next("ul")
        if ul:
            for li in ul.find_all("li"):
                if ":" in li.text:
                    key, val = li.text.split(":", 1)
                    feature_list.append(f"{key.strip()}: {val.strip()}")
    return feature_list

def extract_tags(url):
    soup = get_soup(url)
    tags = [tag.get_text(strip=True) for tag in soup.find_all("a", rel="tag")]
    return tags

def extract_product_images(url):
    soup = get_soup(url)
    image_links = []

    gallery_divs = soup.find_all("div", class_="woocommerce-product-gallery__image")
    for div in gallery_divs:
        img_tag = div.find("img")
        if img_tag and img_tag.get("src"):
            image_links.append(img_tag["src"])

    if not image_links:
        main_img = soup.find("img", class_="wp-post-image")
        if main_img and main_img.get("src"):
            image_links.append(main_img["src"])
    return image_links

def fetch_product_details(url):
    soup = get_soup(url)

    # Ù†Ø§Ù… Ù…Ø­ØµÙˆÙ„
    name_tag = soup.find("h1", class_="product_title")
    product_name = name_tag.text.strip() if name_tag else None

    # Ù‚ÛŒÙ…Øª Ù…Ø­ØµÙˆÙ„
    if "Ù†Ø§Ù…ÙˆØ¬ÙˆØ¯" in soup.text or "ØªÙ…Ø§Ù… Ø´Ø¯" in soup.text:
        product_price = 0
    else:
        price_tag = soup.find("span", class_="woocommerce-Price-amount amount")
        if not price_tag:
            price_tag = soup.find("span", class_="woocommerce-Price-amount")
        product_price = clean_price(price_tag.text) if price_tag else None

    return product_name, product_price


def extract_quantity(product_link):
    resp = requests.get(product_link, timeout=10)
    resp.raise_for_status()
    soup = BeautifulSoup(resp.text, "html.parser")

    # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ø§Ù„Ù…Ø§Ù† Ù…ÙˆØ¬ÙˆØ¯ÛŒ
    # Ù…Ø«Ø§Ù„: span ÛŒØ§ div Ø§ÛŒ Ú©Ù‡ Ù…ØªÙ† "Ø¯Ø± Ø§Ù†Ø¨Ø§Ø±" Ø¯Ø§Ø±Ø¯
    stock_elem = soup.find(lambda tag: tag.name in ["span", "div", "p", "li"] 
                           and "Ø¯Ø± Ø§Ù†Ø¨Ø§Ø±" in tag.get_text())
    if not stock_elem:
        return None

    text = stock_elem.get_text().strip()
    # Ù…ØªÙ† Ù…Ù…Ú©Ù† Ø§Ø³Øª Ù…Ø«Ù„ "128 Ø¯Ø± Ø§Ù†Ø¨Ø§Ø±"
    match = re.search(r"(\d+)\s*Ø¯Ø± Ø§Ù†Ø¨Ø§Ø±", text)
    if match:
        return int(match.group(1))
    else:
        # Ø§Ú¯Ø± ÙØ±Ù…Øª Ù…ØªÙØ§ÙˆØª Ø¨Ø§Ø´Ø¯ØŒ ØªÙ„Ø§Ø´ Ø¯ÛŒÚ¯Ø±ÛŒ
        match2 = re.search(r"(\d+)", text)
        if match2:
            return int(match2.group(1))
    return None


